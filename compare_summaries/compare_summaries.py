import json
from itertools import combinations
from typing import List

from compare_summaries import compare_summaries_utils
from compare_summaries.compare_summaries_params import CompareSummariesParams
from summarize_transcripts import summarize_transcripts_utils
from summarize_transcripts.summarize_transcripts_params import (
    SummarizeTranscriptsParams,
)
from transcribe_audio_chunks import transcribe_audio_chunks_utils


def compare(compare_summaries_params: CompareSummariesParams):
    print("compare summaries...")

    # handle pairs

    transcripts = transcribe_audio_chunks_utils.get_transcripts(
        transcribe_audio_chunks_params=compare_summaries_params.transcribe_audio_chunks_params
    )

    pairs = list(combinations(compare_summaries_params.summaries, 2))

    print(f"num pairs to compare: {len(pairs)}")

    for pair in pairs:
        _compare_two_summaries_and_there_reverse(
            compare_summaries_params=compare_summaries_params,
            summary_params_a=pair[0],  # type: ignore
            summary_params_b=pair[1],  # type: ignore
            transcripts=transcripts,
        )

    print("...compared summaries")


def _compare_two_summaries_and_there_reverse(
    compare_summaries_params: CompareSummariesParams,
    summary_params_a: SummarizeTranscriptsParams,
    summary_params_b: SummarizeTranscriptsParams,
    transcripts: List[str],
):
    print(
        f"comparing summaries {summary_params_a.llm_model_id} vs. {summary_params_b.llm_model_id}..."
    )

    # handle already compared

    if compare_summaries_utils.are_two_summaries_already_compared(
        compare_summaries_params=compare_summaries_params,
        summary_params_a=summary_params_a,
        summary_params_b=summary_params_b,
    ):
        print(f"...summaries already compared")
        return

    # create system prompt

    (
        faithfulness_winner_a_b,
        faithfulness_explanation_a_b,
        coverage_winner_a_b,
        coverage_explanation_a_b,
    ) = _compare_summary_a_and_b(
        compare_summaries_params=compare_summaries_params,
        summary_params_a=summary_params_a,
        summary_params_b=summary_params_b,
        transcripts=transcripts,
    )

    (
        faithfulness_winner_b_a,
        faithfulness_explanation_b_a,
        coverage_winner_b_a,
        coverage_explanation_b_a,
    ) = _compare_summary_a_and_b(
        compare_summaries_params=compare_summaries_params,
        summary_params_a=summary_params_b,
        summary_params_b=summary_params_a,
        transcripts=transcripts,
    )

    comparison_result = {
        "llm_model_id_a": summary_params_a.llm_model_id,
        "llm_model_id_b": summary_params_b.llm_model_id,
        "a_b": {
            "winner_faithfulness": faithfulness_winner_a_b,
            "faithfulness_explanation": faithfulness_explanation_a_b,
            "winner_coverage": coverage_winner_a_b,
            "coverage_explanation": coverage_explanation_a_b,
        },
        "b_a": {
            "winner_faithfulness": faithfulness_winner_b_a,
            "faithfulness_explanation": faithfulness_explanation_b_a,
            "winner_coverage": coverage_winner_b_a,
            "coverage_explanation": coverage_explanation_b_a,
        },
        "faithfulness_is_commutative": _are_results_commutative(
            a_b=faithfulness_winner_a_b, b_a=faithfulness_winner_b_a
        ),
        "coverage_is_commutative": _are_results_commutative(
            a_b=coverage_winner_a_b, b_a=coverage_winner_b_a
        ),
    }

    compare_summaries_utils.add_pair_to_comparison_pairs(
        compare_summaries_params=compare_summaries_params,
        comparison_pair=comparison_result,
    )

    print(f"...compared summaries")


def _compare_summary_a_and_b(
    compare_summaries_params: CompareSummariesParams,
    summary_params_a: SummarizeTranscriptsParams,
    summary_params_b: SummarizeTranscriptsParams,
    transcripts: List[str],
) -> tuple[str, str, str, str]:
    # create system prompt

    system_prompt = """
        You are an AI judge.
        
        YOU WILL RECEIVE:
        1. Several consecutive transcript snippets from the same video.
        2. A candidate summary A of those transcripts generated by an AI model.
        3. Another candidate summary B of those transcripts generated by a different AI model.

        YOUR TASK:
        With respect to the available transcript snippets, compare summary A vs. B in two categories.
        There are three possible results: A is better than B, B is better than A, or its a draw.
        Your judgment must be symmetric.
        Swapping summary A and summary B must not change the result, except for swapping the labels A and B.
        
        1. Category FAITHFULNESS: Faithfulness evaluates whether a summary contains only information supported by the source text, without inventing, adding, or contradicting facts.
        2. Category COVERAGE: Coverage evaluates whether a summary includes the main ideas, arguments, and conclusions from the source text, without omitting essential information.
        
        For each category, give a short explanation for your result.
        
        OUTPUT FORMAT:
        
        Do only output the following JSON
        
        {
            "faithfulness": {
                "explanation": "string",
                "winner": "A" | "B" | "draw"
            },
            "coverage": {
                "explanation": "string",
                "winner: "A" | "B" | "draw"
            }
        }
    """

    # create user prompt

    user_prompt_with_placeholders = """
        TRANSCRIPT SNIPPETS:
        
        {{transcripts}}
    
        CANDIDATE SUMMARY A:
        
        {{candidate_summary_a}}
    
        CANDIDATE SUMMARY B:
        
        {{candidate_summary_b}}
    """

    candidate_summary_a_placeholder_value = summarize_transcripts_utils.get_summary(
        summarize_transcripts_params=summary_params_a
    )
    candidate_summary_b_placeholder_value = summarize_transcripts_utils.get_summary(
        summarize_transcripts_params=summary_params_b
    )

    user_prompt = (
        user_prompt_with_placeholders.replace(
            "{{transcripts}}",
            "\n\n".join(
                [
                    f"Transcript Snippet {transcript_idx}:\n\n{transcript}"
                    for transcript_idx, transcript in enumerate(transcripts)
                ]
            ),
        )
        .replace("{{candidate_summary_a}}", candidate_summary_a_placeholder_value)
        .replace("{{candidate_summary_b}}", candidate_summary_b_placeholder_value)
    )

    # perform comparison

    response = (
        compare_summaries_params.llm_evaluator_system_and_user_prompt_to_response(
            system_prompt, user_prompt
        )
    )

    response_as_json = json.loads(response)

    return (
        response_as_json["faithfulness"]["winner"],
        response_as_json["faithfulness"]["explanation"],
        response_as_json["coverage"]["winner"],
        response_as_json["coverage"]["explanation"],
    )


def _are_results_commutative(a_b: str, b_a: str) -> int:
    if a_b == "A":
        if b_a == "A":
            return 0
        if b_a == "draw":
            return 1
        if b_a == "B":
            return 2

    if a_b == "B":
        if b_a == "B":
            return 0
        if b_a == "draw":
            return 1
        if b_a == "A":
            return 2

    if b_a == "A":
        return 1
    if b_a == "B":
        return 1

    return 2


def calculate_points(comparison_params: ComparisonParams) -> None:
    # init points to 0
    llm_model_id_to_points: dict[str, list[int]] = {}
    for summary in comparison_params.summaries:
        llm_model_id_to_points[summary.llm_model_id] = [0, 0]

    pairs = comparison_params.get_comparison_pairs()

    for pair in pairs:
        llm_model_id_a = pair["llm_model_id_a"]
        llm_model_id_b = pair["llm_model_id_b"]

        if pair["faithfulness_is_commutative"] >= 1:
            if pair["a_b"]["winner_faithfulness"] == "A":
                llm_model_id_to_points[llm_model_id_a][0] += 1
            elif pair["a_b"]["winner_faithfulness"] == "B":
                llm_model_id_to_points[llm_model_id_b][0] += 1
            else:
                llm_model_id_to_points[llm_model_id_a][0] += 0.5
                llm_model_id_to_points[llm_model_id_b][0] += 0.5
        else:
            llm_model_id_to_points[llm_model_id_a][0] += 0.5
            llm_model_id_to_points[llm_model_id_b][0] += 0.5

        if pair["coverage_is_commutative"] >= 1:
            if pair["a_b"]["winner_coverage"] == "A":
                llm_model_id_to_points[llm_model_id_a][1] += 1
            elif pair["a_b"]["winner_coverage"] == "B":
                llm_model_id_to_points[llm_model_id_b][1] += 1
            else:
                llm_model_id_to_points[llm_model_id_a][1] += 0.5
                llm_model_id_to_points[llm_model_id_b][1] += 0.5
        else:
            llm_model_id_to_points[llm_model_id_a][1] += 0.5
            llm_model_id_to_points[llm_model_id_b][1] += 0.5

    print("faithfulness")
    sorted_models = sorted(
        llm_model_id_to_points.items(), key=lambda x: (x[1][0], x[1][1]), reverse=True
    )
    for model, scores in sorted_models:
        print(model, scores)

    print("\n")

    print("coverage")
    sorted_models = sorted(
        llm_model_id_to_points.items(), key=lambda x: (x[1][1], x[1][0]), reverse=True
    )
    for model, scores in sorted_models:
        print(model, scores)
